{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JW notes indicated by # JW "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHBnXM3YVmbq"
   },
   "source": [
    "# ngCASA API and Usage Examples\n",
    "\n",
    "Radio interferometry data analysis applications and algorithms may be assembled from CNGI and ngCASA building blocks. A user may choose to implement their own analysis scripts, use a pre-packaged task similar to those in current CASA or embed ngCASA and CNGI methods in a production pipeline DAG.\n",
    "\n",
    "Below is a (very) preliminary API for ngCASA along with a few examples of applications and algorithms that could form some user-level tasks with interative interfaces. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "glqu7So4Vmb2"
   },
   "source": [
    "## Imaging\n",
    "Iterative Image reconstruction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_QfyfxKb-82"
   },
   "source": [
    "\n",
    "### Imaging API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Is0bHIkOVmb5"
   },
   "outputs": [],
   "source": [
    "def make_imaging_weight(img_dataset,vis_dataset, weightpars):\n",
    "    \"\"\"\n",
    "    Calculate imaging weights for the specified weighting algorithm and image definition \n",
    "    \n",
    "    Options : Natural, Uniform, Robust, Radial\n",
    "    Additional Options : UV-taper.\n",
    "    \n",
    "    Note : The 'mosweight' option may be implemented via the a linear-mosaic in-between the major and minor cycles.\n",
    "    \n",
    "    \"\"\"\n",
    "    # JW  make_imaging_weight does not need an input img_dataset or produce one. I have fleshed out this function.\n",
    "    \n",
    "    \n",
    "def make_gridding_convolution_function(img_dataset, gridpars):\n",
    "    \"\"\"\n",
    "    Calculate gridding convolution functions (GCF) as specified for standard, widefield and mosaic imaging.\n",
    "    Construct a GCF cache (persistent or on-the-fly)\n",
    "    \n",
    "    Options : Choose a list of effects to include\n",
    "            PSterm : Prolate-Spheroidal gridding kernel (anti-aliasing function)\n",
    "            Aterm : Use PB model and Aperture Illumination Function per antenna to construct a GCF per baseline\n",
    "                    ( Include support for Heterogeneous Arrays where Aterm is different per antenna\n",
    "                      Include support for time-varying PB and AIF models. Rotation, etc.)\n",
    "            Wterm : FT of Fresnel kernel per baseline\n",
    "\n",
    "            ( Note : Pointing offsets are applied as phase-gradients during gridding/degridding )\n",
    "            \n",
    "      TBD : W-stack ? How ? \n",
    "            \n",
    "    \"\"\"  \n",
    "    # JW I don't think the we should move phase-gradients and pointing offsets to gridding/degridding. \n",
    "    #Can they be stand alone functions?\n",
    "\n",
    "# JW #####################################################\n",
    "def apply_phase_gradient(vis_dataset, global_dataset, phase_gradient_parms, storage_parms):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    vis_dataset : xarray.core.dataset.Dataset        \n",
    "    \"\"\"  \n",
    "    \n",
    "def apply_pointing_correction(vis_dataset, global_dataset, pointing_correction_parms, storage_parms):\n",
    "    \"\"\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vis_dataset : xarray.core.dataset.Dataset             \n",
    "    \"\"\"  \n",
    "# The global_dataset has the field phasecenters and pointing tables\n",
    "######################################################\n",
    "\n",
    "# JW I think there should also be a function that just makes the grid\n",
    "def make_grid(vis_dataset, grid_parms, storage_parms):\n",
    "    \"\"\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vis_dataset : xarray.core.dataset.Dataset             \n",
    "    \"\"\"  \n",
    "\n",
    "######################################################\n",
    "\n",
    "def make_psf(img_dataset, vis_dataset, gridpars):\n",
    "    \"\"\"\n",
    "    Form a Point Spread Function cube by gridding the imaging weights (with flags) and an inverse Fourier transform\n",
    "    \n",
    "    (A cube with 1 channel is a continuum image (nterms=1))   \n",
    "    \"\"\"\n",
    "    ngcasa.imaging._make_grid()\n",
    " # JW It's the users responsibility to apply flags. The gridder only looks for nans.\n",
    "    \n",
    "def make_pb(img_dataset,vis_dataset,gridpars):\n",
    "    \"\"\"\n",
    "    Construct a Primary Beam cube containing a weighted sum of primary beams\n",
    "    Option 1 : Evaluate models directly onto the image (for common PBs)\n",
    "    Option 2 : Inverse FT each gridding convolution function (for varying PBs)\n",
    "\n",
    "    (A cube with 1 channel is a continuum image (nterms=1))\n",
    "    \"\"\"   \n",
    "\n",
    "def make_residual_image(img_dataset, vis_dataset,gridpars, normpars):\n",
    "    \"\"\"\n",
    "    Form a residual image cube by gridding and inverse FTing the data - model.\n",
    "    Use a pre-specified gridding convolution function cache.\n",
    "\n",
    "    (A cube with 1 channel is a continuum image (nterms=1))\n",
    "\n",
    "    \"\"\"   \n",
    "    cngi.vis.uvsub() # do the subtraction of data-model or corrected-model, etc etc..\n",
    "    ngcasa.imaging._make_grid() \n",
    "    cngi.image.fourier_transform()\n",
    "    cngi.image.corr_to_stokes() \n",
    "    ngcasa.imaging._normalize(direction='reverse') # (1) Do the multiply/div by PB, accounting for masks.\n",
    "# JW I think this should be a higher level function. Is there a need for cngi.vis.uvsub (it is just a dask numpy substraction)?\n",
    "    \n",
    "def make_image(img_dataset, vis_dataset,gridpars, arr_name):\n",
    "    \"\"\"\n",
    "    Form an image cube by gridding and inverse FTing the data in the specified arr_name\n",
    "    Use a pre-specified gridding convolution function cache.\n",
    "    \n",
    "    (A cube with 1 channel is a continuum image (nterms=1))\n",
    "    \"\"\"   \n",
    "    ngcasa.imaging._make_grid() \n",
    "    cngi.image.fourier_transform()\n",
    "# JW I have fleshed out this function.\n",
    "\n",
    "        \n",
    "def predict_modelvis_image(img_dataset, vis_dataset, gridpars, normpars, arr_name, incremental):     \n",
    "    \"\"\"\n",
    "    Predict model visibilities from an input model image cube (units Jy/pixel) using\n",
    "    a pre-specified gridding convolution function cache.\n",
    "    Save the model visibilities in arr_name (default = 'MODEL')\n",
    "    Optionally overwrite the model or add to existing model (incremental=T)\n",
    "    \n",
    "    (A input cube with 1 channel is a continuum image (nterms=1))\n",
    "\n",
    "    \"\"\"   \n",
    "    ngcasa.imaging._normalize(direction='forward') # Apply PB models to go to flat-sky\n",
    "    cngi.image.stokes_to_corr()\n",
    "    cngi.image.fourier_transform()\n",
    "    ngcasa.imaging._degrid()  \n",
    "\n",
    "    \n",
    "def predict_modelvis_component(img_dataset, vis_dataset, arr_name, incremental):\n",
    "    \"\"\"\n",
    "    Predict model visibilities from a component list by analytical evaluation\n",
    "    Apply PB models to the components prior to evaluation.\n",
    "    Save the model visibilities in arr_name (default = 'MODEL')\n",
    "    Optionally overwrite the model or add to existing model (incremental=T)\n",
    "\n",
    "    \"\"\"   \n",
    "\n",
    "        \n",
    "def make_mask(img_dataset,maskpars,interactive=False):\n",
    "    \"\"\"\n",
    "    Make a region to identify a mask for use in deconvolution. \n",
    "    \n",
    "    One or more of the following options are allowed\n",
    "    - Supply a mask in the form of a cngi.image.region\n",
    "    - Run an auto-masking algorithm to detect structure and define a cngi.image.region\n",
    "    - Apply a pblimit based mask\n",
    "\n",
    "    An existing deconvolution mask from img_dataset may either be included in the above, or ignored. \n",
    "\n",
    "    The output is a region (array?) in the img_dataset containing the intersection of all above regions \n",
    "    \n",
    "    (Note : Interactive masking is handled separately at the application layer, editing the region directly). \n",
    "\n",
    "    \"\"\"   \n",
    "# JW I don't think interactive should be a parameter\n",
    "    \n",
    "def is_converged(img_dataset, iterpars, iter_rec):\n",
    "    \"\"\"\n",
    "    An iteration controller for image reconstruction\n",
    "    \n",
    "    The current image set (residual, psf, model, etc) is evaluated against stopping criteria derived \n",
    "    from input parameters (iterpars) and the image set itself. \n",
    "    \n",
    "    Step 1 : Derive stopping criteria\n",
    "    \n",
    "    - Merge explicit user-parameters in iterpars (niter,threshold,etc..) with criteria that are calculated from\n",
    "      the imageset (psfsidelobelevel, cyclethreshold, N-sigma-based thresholds, mask-sensitive thresholds)\n",
    "    - Calculate 'cycleniter' and 'cyclethreshold' to be used in Step 2. \n",
    "    \n",
    "    Step 2 : Apply stopping criteria (as an ordered list)\n",
    "       \n",
    "    - Peak residual within the mask region for imagename.residual <= threshold\n",
    "    - Total iters done >= niter\n",
    "        \n",
    "    \n",
    "    Outputs : \n",
    "    \n",
    "    (1) Return a dict {'cyclethreshold':xxx, 'cycleniter':xxx', 'stopcode':xxx} \n",
    "        to be used for the subsequent minor cycle and/or \n",
    "        to indicate that a stopping criterion was satisfied.  \n",
    "        \n",
    "    (2) Save or append-to a 'convergence history' dictionary. TBD : Where should this dict live ?  \n",
    "        This content is what gets printed to logs, plotted in an interactive GUI, \n",
    "        and forms a long-lived record of how the image reconstruction proceeded.    \n",
    "    \n",
    "    \"\"\"   \n",
    "    return {}\n",
    "# JW My suggestion is that is_converged returns the img_dataset with the convergence history list of dict included in the attribute section.\n",
    "\n",
    "def deconvolve_point_clean(img_dataset, decpars):\n",
    "    \"\"\"\n",
    "    An iterative solver to construct a model from an observed image(set) and psf(set).\n",
    "    \n",
    "    Sky model : Point source\n",
    "    Algorithm : CLEAN (a greedy algorithm for chi-square minimization)\n",
    "       \n",
    "    Options : Hogbom, Clark\n",
    "    \n",
    "    Input : Requires an input cube (mfs is a cube with nchan=1)\n",
    "    Output : Cube model image    \n",
    "    \"\"\"   \n",
    "    \n",
    "def deconvolve_multiterm_clean(img_dataset, decpars):\n",
    "    \"\"\"\n",
    "    An iterative solver to construct a model from an observed image(set) and psf(set).\n",
    "    \n",
    "    Sky model : A (multi-term) linear combination of basis functions.\n",
    "                Multi-scale : Basis functions are inverted tapered paraboloids\n",
    "                Multi-scale MFS : Basis functions are Taylor polynomials in frequency\n",
    "    \n",
    "\n",
    "    Options : \n",
    "     - MS-Clean : Multi-scale CLEAN ( MS-MFS Clean with nterms=1 )\n",
    "                  Input : Requires an input cube (mfs is a cube with nchan=1)\n",
    "                  Output : Cube model image\n",
    "                  \n",
    "     - MS-MFS Clean : Wideband Imaging that solves for a set of Taylor coefficient maps.\n",
    "                  Input : Multi-channel cube.\n",
    "                  Output : Taylor coefficient maps, Spectral Index + Evaluation of the model to a Cube model image\n",
    "                  \n",
    "                  Step (1) cngi.image.cube_to_mfs()\n",
    "                  Step (2) Implement the multi-term deconvolution algorithm\n",
    "                  Step (3) cngi.image.mfs_to_cube()\n",
    "     \n",
    "    The special case of nscales=1 and nterms=1 is the same use-case as deconvolve_point_clean.\n",
    "    \"\"\"   \n",
    "    \n",
    "def deconvolve_adaptive_scale_pixel(img_dataset, decpars):\n",
    "    \"\"\"\n",
    "    An iterative solver to construct a 2D mixed model from an observed image(set) and psf(set).\n",
    "    \n",
    "    Sky Model : A linear combination of 2D Gaussians\n",
    "    Algorithm : Chi-square / TV minimization on atom parameters, with subspace selections.\n",
    "       \n",
    "    Options : Narrow-band, Wide-band\n",
    "    \n",
    "    Input : Requires an input cube (mfs is a cube with nchan=1)\n",
    "    Output : Cube model image  and/or a list of flux components.   \n",
    "\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "def deconvolve_fast_resolve(img_dataset, decpars):\n",
    "    \"\"\"\n",
    "    An iterative solver to construct a Bayesian model from an observed image(set) and psf(set).\n",
    "    \n",
    "    Sky Model : Pixel amplitudes\n",
    "    Algorithm : Bayesian formulation that includes constraints on the flux distribution and wideband support.\n",
    "        \n",
    "    Input : Requires an input cube (mfs is a cube with nchan=1)\n",
    "    Output : Cube model image, Error map (Spectral index map)\n",
    "\n",
    "    \"\"\"   \n",
    "\n",
    "def deconvolve_rotation_measure_clean(img_dataset, decpars):\n",
    "    \"\"\"\n",
    "    An iterative solver to construct a full-polarization model from an observed image(set) and psf(set).\n",
    "\n",
    "    Sky Model : Per flux component, delta-functions in lambda-square space\n",
    "    Algorithm : \n",
    "        Step (1) : Transform the cube to lambda-square space\n",
    "        Step (2) : Construct a 3D RM-synthesis PSF\n",
    "        Step (3) : Run CLEAN based-deconvolution\n",
    "        Step (4) : Transform back to frequency space.\n",
    "   \n",
    "    Input : Requires an input cube (mfs is a cube with nchan=1)\n",
    "    Output : Cube model image, Error map (Spectral index map)\n",
    "\n",
    "    \"\"\"   \n",
    "\n",
    "\n",
    "def restore_model(img_dataset, restorepars):\n",
    "    \"\"\"\n",
    "    Restore a deconvolved model.\n",
    "    \n",
    "    Inputs : target resolution could be native or 'common' or explicitly specified.\n",
    "    \n",
    "    Cube and single-term imaging : \n",
    "    - Smooth the model image (Jy/pixel) to the target resolution\n",
    "    - Smooth the residual image (Jy/beam) to the target resolution\n",
    "    - Add the two smoothed images\n",
    "    \n",
    "    Multi-term imaging :\n",
    "    - Smooth the model taylor coefficient images to the target resolution\n",
    "    - Apply the inverse Hessian to the residual image vector (data-space to model-space)\n",
    "      (At non-native target resolution, also compute a new Hessian matched to the scale of the restoring beam.)\n",
    "    - Smooth the model-space residuals to the target resolution\n",
    "    \n",
    "    Re-restoration may be done simply by calling this same method again with a different target resolution. \n",
    "    Calculations will start with the native model and residual images. \n",
    "    Note that re-restoration with cngi.image.imsmooth() will not be accurate for multi-term imaging. \n",
    "    \"\"\"   \n",
    "\n",
    "    \n",
    "def make_sd_residual_image():\n",
    "    \"\"\"\n",
    "    Construct an observed single dish image cube from single-dish data\n",
    "    \n",
    "    If a model image is supplied, implement : \n",
    "        Residual image = Observed image - { Model image (conv) SD PSF }\n",
    "    \n",
    "    \"\"\"   \n",
    "# JW The substraction should be done by the user. make_sd_image\n",
    "    \n",
    "def make_sd_point_spread_function():\n",
    "    \"\"\"\n",
    "    Construct a single dish PSF image cube, containing the effective SD beam per frequency.\n",
    "    \"\"\"   \n",
    "def make_sd_weight_image():\n",
    "    \"\"\"\n",
    "    Construct a single dish weight map that illustrates the observing pattern of the mosaic. \n",
    "    \"\"\"   \n",
    "    \n",
    "def feather(img_dataset_lowres, img_dataset_highres):\n",
    "    \"\"\"\n",
    "    Feather two images together, based on restoring beam information stored in both. \n",
    "    \n",
    "    Output image = iFT( FT(lowres_image) + [1-FT(lowres_beam)] x FT(highres_image) )\n",
    "    \n",
    "    TBD : Do this for the entire image_set (psf, image) and updated restoring-beam information as well ? \n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "def linear_mosaic(img_datasets, img_mosaic):\n",
    "    \"\"\"\n",
    "    Construct a linear mosaic as a primary-beam weighted sum of a set of input images. \n",
    "    Individual images are re-sampled onto a larger image grid and summed.\n",
    "       \n",
    "    Assume flat-noise normalization for the inputs.  ( TBD : Or flatsky? )\n",
    "    \n",
    "    Output image :  sum( input_images ) / sum ( input_pbs )\n",
    "    \n",
    "    TBD : This requires some sort of merging of img_datasets. \n",
    "          ? CNGI demo on how to append/add images to an image_set and ensure that meta-data are consistent ?\n",
    "    \n",
    "    \"\"\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc2JSmJlVmcR"
   },
   "source": [
    "### Imaging Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8W8PKCMVmcT"
   },
   "outputs": [],
   "source": [
    "def _normalize(direction, normtype):\n",
    "    \"\"\"\n",
    "    PB normalization on the cubes \n",
    "    \n",
    "    direction : 'forward''reverse'\n",
    "    normtype : 'flatnoise','flatsky','common','pbsquare'\n",
    "    \n",
    "    Multiply and/or divide by PB models, accounting for masks/regions.\n",
    "    \n",
    "    \"\"\"\n",
    "def _grid_cube(type={'psf','obs','res','pbweight'}):\n",
    "    \"\"\"\n",
    "    Do the gridding\n",
    "\n",
    "    Use the Gridding convolution function from the cache, and apply phase-gradients for pointing offsets.\n",
    "\n",
    "            Pointing Offset : Phase gradient across the GCF (from pointing meta-data or pointing_cal_dataset)\n",
    "                    ( Include support for Heterogeneous Arrays where pointing offset varies with antenna\n",
    "                      Include support for time-varying offsets : read from Pointing meta-data)\n",
    "\n",
    "            Mosaic Offset : Phase gradient across the GCF + UVW-rotation to move data to image phasecenter.\n",
    "    \n",
    "    Note : A cube with one channel = mfs with nterms=1 \n",
    "    \n",
    "    (TBD : This method has to be call-able from outside of imager, for example, for auto-flagging. Where to locate it ?).\n",
    "    \"\"\"\n",
    "    \n",
    "def _degrid_model_cube():\n",
    "    \"\"\"\n",
    "    Do the de-gridding\n",
    "    Note : A cube with one channel = mfs with nterms=1 \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "# JW I have not created these files since they are not part of the api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRYeNaBIVmcg"
   },
   "source": [
    "### Methods to move down into CNGI.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oThCvHwRVmci"
   },
   "outputs": [],
   "source": [
    "def cube_to_mfs(img_dataset, nterms):\n",
    "    \"\"\"\n",
    "    Collapse a cube to a continuum image (set)\n",
    "    \n",
    "    Based on 'nterms', evaluate Taylor-weighted sums across frequency. \n",
    "    (In casa6, casatasks.sdintimaging contains a python cube_to_taylor() implementation )\n",
    "    \n",
    "    To be used as a convertor during image reconstruction, and also stand-alone.\n",
    "    \n",
    "    \"\"\"   \n",
    "\n",
    "def mfs_to_cube(img_dataset, nterms):\n",
    "    \"\"\"\n",
    "    Expand a continuum image to a cube\n",
    "    \n",
    "    Based on 'nterms', evaluate a Taylor polynomial across frequency in the output cube.\n",
    "    (In casa6, casatasks.sdintimaging contains a python cube_to_taylor() implementation )\n",
    "    \n",
    "    To be used as a convertor during image reconstruction, and also stand-alone.\n",
    "    \n",
    "    \"\"\"   \n",
    "\n",
    "def corr_to_stokes(img_dataset):\n",
    "    \"\"\"\n",
    "    Convert from the correlation basis (XX,YY,XY,YX) or (RR,LL,LR,RL) to the Stokes basis (I,Q,U,V)\n",
    "       \n",
    "    To be used as a convertor during image reconstruction, and also stand-alone\n",
    "    \"\"\"   \n",
    "    \n",
    "def stokes_to_corr(img_dataset):\n",
    "    \"\"\"\n",
    "    Convert from Stokes basic (I,Q,U,V) to a specified correlation basis (XX,YY,XY,YX) or (RR,LL,LR,RL)\n",
    "       \n",
    "    To be used as a convertor during image reconstruction, and also stand-alone    \n",
    "    \"\"\"   \n",
    "\n",
    "    \n",
    "def fourier_transform(img_dataset):\n",
    "    \"\"\"\n",
    "    A 2D Fourier transform\n",
    "    \n",
    "    Numbers : np.fft.fftshift( np.fft.fftn(np.fft.ifftshift( input_array ))  )\n",
    "    \n",
    "    Image Coordinate System : Convert as appropriate to 'UV' coordinates with uv-cell size. \n",
    "\n",
    "    \"\"\"   \n",
    "# JW not yet added to cngi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfql-mO6Vmcs"
   },
   "source": [
    "### Imaging Examples\n",
    "\n",
    "These examples relate to the different types of images listed in https://casa.nrao.edu/casadocs/casa-5.0.0/synthesis-imaging/image-definition\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-k-jHIrSXg"
   },
   "source": [
    "#### Cube and Continuum (narrow-field, wide-field and joint-mosaic)\n",
    "Example : Cube or Continuum imaging (nterms=1 and nterms>1) for narrow-field, wide-field and joint mosaic imaging, including visibility pre-processing for topo-lsrk conversion and automasking.  This is a pipeline imaging use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tb1JVOfgVmcx"
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------- Data Selection\n",
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "# JW cngi.dio.read_vis does not do selection. I don't know how necessary this function is. All it does is wrap open_zarr()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------- Visibility Preprocessing\n",
    "# topo->lsrk + channel binning + ephemeris sources\n",
    "cngi.vis.regridspw(vis_dataset, impars)\n",
    "# Apply flags for all future steps\n",
    "cngi.vis.applyflags(vis_dataset)\n",
    "# Phasecenter rotation\n",
    "cngi.vis.rotateuvw(vis_dataset) # TBD : Here, or inside _make_grid ?  \n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------- Image Definition\n",
    "# Construct an empty image set\n",
    "img_dataset = cngi.dio.write_image(impars)\n",
    "# Set image weighting scheme \n",
    "ngcasa.imaging.make_imaging_weight(img_dataset, weightpars)\n",
    "# Define gridding convolution functions. Aterm, Wterm, JointMosaic are specified here.\n",
    "ngcasa.imaging.make_gridding_convolution_function(img_dataset, gridpars)\n",
    "\n",
    "#--------------------------------------------------------------------- Make initial images\n",
    "# Make PSF\n",
    "ngcasa.imaging.make_psf(img_dataset, vis_dataset, gridpars)\n",
    "# Make PB\n",
    "ngcasa.imaging.make_pb(img_dataset,vis_dataset,gridpars)\n",
    "# Make Residual image and normalize it\n",
    "ngcasa.imaging.make_residual_image(img_dataset,vis_dataset, gridpars, normpars)\n",
    "\n",
    "#------------------------------------------------------------------ Iteration Control\n",
    "# Initialize the mask\n",
    "ngcasa.imaging.make_mask(img_dataset,maskpars)\n",
    "# < Interactive Clean GUI >\n",
    "# Check convergence criteria\n",
    "iter_rec = ngcasa.imaging.is_converged(img_dataset, iterpars, None)\n",
    "\n",
    "\n",
    "# Perform iterative reconstruction\n",
    "while( iter_rec['stopcode']=='continue' ):\n",
    "    # -----------------------------------------------------------------------Minor cycle\n",
    "    exec_rec = ngcasa.imaging.deconvolve_point(img_dataset, decpars, iter_rec)\n",
    "    #-----------------------------------------------------------------------------------\n",
    "    \n",
    "    # -----------------------------------------------------------------------Major cycle\n",
    "    # Model prediction\n",
    "    ngcasa.imaging.predict_modelvis_image(img_dataset, vis_dataset, normpars, gridpars)\n",
    "    # Make residual image and normalize it.\n",
    "    ngcasa.imaging.make_residual_image(img_dataset,vis_dataset, gridpars,normpars)\n",
    "    #-----------------------------------------------------------------------------------\n",
    "\n",
    "    #------------------------------------------------------------------Iteration Control\n",
    "    # Update the mask\n",
    "    ngcasa.imaging.make_mask(img_dataset,maskpars)\n",
    "    # < Interactive Clean GUI >\n",
    "    # Check convergence criteria\n",
    "    iter_rec = ngcasa.imaging.is_converged(img_dataset, iterpars, exec_rec)\n",
    "    #-----------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "#------------------------------------------------------------------    Restoration\n",
    "# Restore the model image\n",
    "ngcasa.imaging.restore_model(img_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmcQEaQsVmc7"
   },
   "source": [
    "#### Other imaging algorithms (multi-term, rm-synthesis)\n",
    "\n",
    "Wide-band multi-term imaging with wideband pb-correction may be run by setting up a cube major cycle followed by deconvolve_multiterm.\n",
    "\n",
    "Rotation-measure synthesis may be called by setting up a full-stokes cube major cycle, followed by a deconvolve_rotation_measure_clean\n",
    "\n",
    "In both these cases, the deconvolution algorithm starts with an image cube, transforms the image into the sky model space (sparse basis), performs the deconvolution in that space, and transforms the model back to the cube in preparation for the next major cycle.   Wideband Primary beam correction (for Stokes I) is done simply by ensuring 'flatsky' or 'commonpb' normaliation at the end of the make_residual step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfAvXT-2PCza"
   },
   "outputs": [],
   "source": [
    "# Prepare the residual image cube : Normalize to a common pb. This implements widebandpbcor. \n",
    "ngcasa.imaging.make_residual_image(img_dataset,vis_dataset, gridpars, normtype='commonpb')\n",
    "\n",
    "# Start iterative deconvolution...\n",
    "\n",
    "    # Run the deconvolver (input : residual and psf cubes, output : model cube)\n",
    "    ngcasa.imaging.deconvolve_multiterm_clea(img_dataset)\n",
    "\n",
    "    # Model prediction\n",
    "    ngcasa.imaging.predict_modelvis_image(img_dataset, vis_dataset, normpars, gridpars)\n",
    "\n",
    "    # Make residual image and normalize gain\n",
    "    ngcasa.imaging.make_residual_image(img_dataset,vis_dataset, gridpars,normtype='commonpb') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCOmXBK1Vmc9"
   },
   "source": [
    "#### Interactive Clean\n",
    "\n",
    "There are two parts to interactive image reconstruction.\n",
    "\n",
    "(1) Mask drawing/viewing : Use a GUI to interactively draw a mask or to simply visualize the current mask. This may be used in conjunction with the ngcasa.imaging.make_mask() to view and/or edit the resulting region.\n",
    "\n",
    "(2) Editing iteration control parameters at run-time : The same GUI used for mask visualization may be used to display and accept edited values for user-parameters. \n",
    "\n",
    "In the above example, this interactive step would reside in between 'Update Mask' and 'Check convergence criteria'. \n",
    "\n",
    "See https://gitlab.nrao.edu/rurvashi/interactive-imaging-with-casa6  for an example (using casa6) of how this may be achieved via a stand-alone call to a GUI in-between the major and minor cycles. Convergence history may also be displayed at this stage, allowing for an interactive user to decide if iteration-control parameters should change or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D42kac-sVmc_"
   },
   "source": [
    "#### Linear Mosaics and Joint mosaics\n",
    "\n",
    "Three options exist.\n",
    "\n",
    "(1) The gridder allows for joint mosaic phase gradients to be applied to gridding convolution functions. No change to the code shown above. This is equivalent to mosweight=False in casa6.casatasks.tclean()\n",
    "\n",
    "(2) ngcasa.imaging.linear_mosaic may be used to combine restored images from different pointings (or clusters of joint-mosaic pointings). This is a post-deconvolution step.\n",
    "\n",
    "(3) Use cngi.image.linear_mosaic() to calculate a weighted sum of images from different pointing subsets, in-between the major and minor cycles. \n",
    "- This option has the advantage of allowing smaller image sizes for individual gridder calls.\n",
    "- This implicitly implements 'mosweight=True' of casa6.casatasks.tclean() because each pointing (or subset of pointings) is gridded and normalized separately. \n",
    "\n",
    "TBD : Will we get (3) by using (1) but just choosing the partition axis to be along fields ? Almost, but no imsize reduction, and it will always be mosweight=False. \n",
    "\n",
    "Below is an implementation of (3). TBD : Can this be simplified ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JW If we add the field as an image and grid dimension this can be simplified (d0,d1,wstack,field,chan,pol). The will then require two more grid parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLFnDu2XVmdA"
   },
   "outputs": [],
   "source": [
    "## Image Reconstruction with Linear Mosaics before deconvolution.\n",
    "## Major cycle runs separately for each pointing (or subset of pointings)\n",
    "## Minor cycle runs on a joint image.\n",
    "\n",
    "img_datasets={}\n",
    "\n",
    "for imfield in list_of_fields:\n",
    "    \n",
    "    # Construct a selected vis dataset for one pointing (or subset of pointings)\n",
    "    vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "    ### Code blocks from above for visibility preprocessing, image definition, make_psf, make_pb. \n",
    "    cngi.vis.regridspw(vis_dataset, impars)\n",
    "    cngi.vis.applyflags(vis_dataset)\n",
    "    cngi.vis.rotateuvw(vis_dataset) # TBD : Here, or inside _make_grid ? \n",
    "    img_dataset = cngi.dio.write_image(impars)\n",
    "    ngcasa.imaging.make_imaging_weight(img_dataset, weightpars)\n",
    "    ngcasa.imaging.make_gridding_convolution_function(img_dataset, gridpars)\n",
    "    ngcasa.imaging.make_psf(img_dataset, vis_dataset, gridpars)\n",
    "    ngcasa.imaging.make_pb(img_dataset,vis_dataset,gridpars)    \n",
    "    \n",
    "    # Make Residual image and normalize it (normalizing per pointing => mosweight=True)\n",
    "    ngcasa.imaging.make_residual_image(img_dataset,vis_dataset, gridpars, normpars)\n",
    "    \n",
    "    # Accumulate image datasets for each pointing (or subset of pointings)\n",
    "    img_datasets[imfield] =  img_dataset\n",
    "    \n",
    "# Do a linear mosaic to generate the image to send to the minor cycle\n",
    "cngi.image.linear_mosaic(img_datasets, img_linmos)\n",
    "\n",
    "# Setup iteration control and masks\n",
    "ngcasa.imaging.make_mask(img_linmos,maskpars)\n",
    "iter_rec = ngcasa.imaging.is_converged(img_linmos, iterpars, None)\n",
    "\n",
    "# Perform iterative deconvolution\n",
    "while( iter_rec['stopcode']=='continue' ):\n",
    "    exec_rec = ngcasa.imaging.deconvolve_point(img_linmos, decpars, iter_rec)\n",
    "\n",
    "    for imfield in list_of_fields:\n",
    "        # Regrid the linmos model image onto subset model images\n",
    "        cngi.image.regrid(img_linmos, img_datasets[imfield])\n",
    "        # Model prediction\n",
    "        ngcasa.imaging.predict_modelvis_image(img_datasets[imfield], vis_dataset, normpars, gridpars)\n",
    "        # Make residual image and normalize it.\n",
    "        ngcasa.imaging.make_residual_image(img_datasets[imfield],vis_dataset, gridpars,normpars)\n",
    "\n",
    "    # Do a linear mosaic to generate the image to send to the minor cycle\n",
    "    cngi.image.linear_mosaic(img_datasets, img_linmos)\n",
    "    \n",
    "    # Update iteration control and masks\n",
    "    ngcasa.imaging.make_mask(img_dataset,maskpars)\n",
    "    iter_rec = ngcasa.imaging.is_converged(img_dataset, iterpars, exec_rec)\n",
    "\n",
    "    \n",
    "#------------------------------------------------------------------    Restoration\n",
    "# Restore the model image\n",
    "ngcasa.imaging.restore_model(img_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-OaMgVaVmdN"
   },
   "source": [
    "#### Multi-field Imaging\n",
    "\n",
    "Purpose : To image outlier sources in separate small images in addition to the main large image. \n",
    "\n",
    "Use-Cases : \n",
    "- A bright outlier source far from the region of interest would cause the image size to greatly increase if imaged as part of a single image. This single large image would also likely be mostly empty. \n",
    "- A bright outlier source requires a different gridding or deconvolution algorithm from the main field, but must be part of the same reconstruction run. A continuum detection experiment at the center of the field would require nterms=1 with (say) multiscale clean, but a bright point source at the half-power level of the primary beam has strong spectral structure induced by the primary beam. In this case, there is no interest in flux accuracy of the bright outlier source, but it must be modeled and subtracted. A multi-term point-source deconvolution algorithm with the standard gridder may be used on the outlier source while a multi-scale nterms=1 imaging run is done on the main field. \n",
    "\n",
    "Algorithm Steps : \n",
    "  - (1) The same data are gridded onto multiple uv-grids to form a list of observed images and psfs. \n",
    "  -  (2) Each such image_field is deconvolved separately in the image domain.  \n",
    "  -  (3) Iteration control must be merged across image_fields. The return dicts from ngcasa.imaging.has_converged() for each image_field must be merged before parameters are sent to the individual deconvolvers. \n",
    "  -  (4) Model images from all image_fields are reconciled to handle overlap regions.\n",
    "  (In case of overlap, use the specified order of the input image_fields to indicate precedence and to blank out overlapping model image pixels for all but one image_field. Or, apply weights. )\n",
    "  -  (5) Predict model visibilities separately for each image_field, adding to the model_data array in the vis_dataset.  \n",
    "\n",
    "Steps 1,2,5 are done independently per image_field. \n",
    "Steps 3 and 4 implement the desired relation between these fields for iteration-control and in model-prediction. \n",
    "\n",
    "Below is an implementation. TBD : Can this be simplified ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5c3V81TrVmdO"
   },
   "outputs": [],
   "source": [
    "## Image Reconstruction with Multi-Field imaging\n",
    "## Major cycle runs once, using models predicted from all image fields.\n",
    "## Minor cycle runs separately on each image-field\n",
    "\n",
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "# Visibility pre-processing : topo->lsrk + channel binning\n",
    "cngi.vis.regridspw(vis_dataset, impars)\n",
    "# Apply flags for all future steps\n",
    "cngi.vis.applyflags(vis_dataset)\n",
    "\n",
    "# Construct a list of empty image sets\n",
    "img_datasets={}\n",
    "for i in range(N_field):\n",
    "    img_datasets[i] = cngi.dio.write_image(impars[i]) \n",
    "\n",
    "# Set image weighting scheme \n",
    "ngcasa.imaging.make_imaging_weight(img_datasets[0], weightpars)\n",
    "# Define gridding convolution functions. Aterm, Wterm, JointMosaic are specified here.\n",
    "ngcasa.imaging.make_gridding_convolution_function(img_dataset, gridpars)\n",
    "\n",
    "iter_recs={}\n",
    "for i in range(N_field):\n",
    "    # Make PSF\n",
    "    ngcasa.imaging.make_psf(img_dataset[i], vis_dataset, gridpars)\n",
    "    # Make PB\n",
    "    ngcasa.imaging.make_pb(img_dataset[i],vis_dataset,gridpars)\n",
    "    # Make Residual image and normalize it\n",
    "    ngcasa.imaging.make_residual_image(img_dataset[i],vis_dataset, gridpars, normpars)\n",
    "\n",
    "    # Initialize the mask and iteration control\n",
    "    ngcasa.imaging.make_mask(img_dataset[i],maskpars)\n",
    "    iter_recs[i] = ngcasa.imaging.is_converged(img_linmos, iterpars, None)\n",
    "\n",
    "\n",
    "# Merge iteration control rules/parameters across fields\n",
    "## Implement logic here to reconcile all iter_recs[] into a single iter_rec to apply to all fields. \n",
    "    \n",
    "# Perform iterative reconstruction\n",
    "while(iter_rec['stopcode']=='continue'):\n",
    "    for i in range(N_field):\n",
    "        ngcasa.imaging.deconvolve(img_dataset[i], decpars)\n",
    "\n",
    "    # Implement code to handle overlapping regions in the model list. \n",
    "    # Use list ordering to pick only the first model and blank overlapping regions in other model images   \n",
    "\n",
    "    ## Model prediction (incremental additions)\n",
    "    for i in range(N_field):\n",
    "        ngcasa.imaging.predict_modelvis_image(img_dataset[i], vis_dataset, normpars, gridpars, incremental=True)\n",
    "\n",
    "    for i in range(N_field):\n",
    "        ## Make residual image and normalize it.\n",
    "        ngcasa.imaging.make_residual_image(img_dataset[i],vis_dataset, gridpars,normpars)\n",
    "\n",
    "        # Update the mask\n",
    "        ngcasa.imaging.make_mask(img_dataset[i],maskpars,interactive=T/F)\n",
    "    \n",
    "# Restore the model images\n",
    "for i in range(N_field):\n",
    "    ngcasa.imaging.restore_model(img_dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvkE0WILVmdV"
   },
   "source": [
    "#### Single Dish Imaging with Deconvolution\n",
    "Purpose : To remove the effect of the Single Dish effective beam from the observed images.\n",
    "\n",
    "Algorithm Steps : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPrPxrA5VmdW"
   },
   "outputs": [],
   "source": [
    "## Open datasets and pre-process as needed\n",
    "\n",
    "# Make the observed image\n",
    "ngcasa.imaging.make_single_dish_residual(img_dataset)\n",
    "# Make the PSF\n",
    "ngcasa.imaging.make_single_dish_psf(img_dataset)\n",
    "    \n",
    "# Initialize the mask and iteration control\n",
    "ngcasa.imaging.make_mask(img_dataset,maskpars)\n",
    "iter_rec = ngcasa.imaging.is_converged(img_dataset, iterpars, None)\n",
    "\n",
    "# Perform iterative reconstruction\n",
    "while( iter_rec['stopcode']=='continue' ):\n",
    "    # Minor Cycle\n",
    "    exec_rec = ngcasa.imaging.deconvolve_multiterm clean(img_dataset, decpars, iter_rec) # MSClean or MSMFS.\n",
    "\n",
    "    # Major Cycle \n",
    "    ngcasa.imaging.make_single_dish_residual(img_dataset)\n",
    "    \n",
    "    # Update the mask and iteration control\n",
    "    ngcasa.imaging.make_mask(img_dataset,maskpars)\n",
    "    iter_rec = ngcasa.imaging.is_converged(img_dataset, iterpars, exec_rec)\n",
    "\n",
    "# Restore the model image\n",
    "ngcasa.imaging.restore_model(img_dataset)\n",
    "\n",
    "## This example does not use the sd_weight_image(). TBD : Update to use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ek8qw4nPVmdf"
   },
   "source": [
    "#### Joint Single Dish and Interferometer Imaging\n",
    "\n",
    "Purpose : To use constraints from both INT and SD datasets during a joint reconstruction. \n",
    "\n",
    "Algorithm Steps : \n",
    "\n",
    "(1) Construct Cube PSFs and Residual Images from INT and SD datasets separately.\n",
    "\n",
    "(2) Apply cngi.image.feather() to merge them and produce a new img_set containing joint information.\n",
    "\n",
    "(3) Minor cycle : ngcasa.imaging.deconvolve()\n",
    "\n",
    "(4) Iteration control and masking : Same as interferometer imaging\n",
    "\n",
    "(5) Major cycle\n",
    "     - For INT, follow the same process as in the example above\n",
    "     - For SD, Residual image = Observed image - { Model image (conv) SD PSF }\n",
    "     Call cngi.image.feather() to merge the new residual images.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzlZzjvVVmdh"
   },
   "outputs": [],
   "source": [
    "## Open datasets and pre-process as needed\n",
    "\n",
    "# Make the observed SD image\n",
    "ngcasa.imaging.make_single_dish_residual(sd_imset)\n",
    "# Make the SD PSF\n",
    "ngcasa.imaging.make_single_dish_psf(sd_imset)\n",
    "\n",
    "# Make the INT PSF\n",
    "ngcasa.imaging.make_psf(int_imset, vis_dataset, gridpars)\n",
    "# Make the INT PB\n",
    "ngcasa.imaging.make_pb(int_imset, vis_dataset,gridpars)\n",
    "# Make INT Residual image and normalize it\n",
    "ngcasa.imaging.make_residual_image(int_imset, vis_dataset, gridpars, normpars)\n",
    "\n",
    "    \n",
    "# Feather the SD and INT Cubes together ( PSF and Residual )\n",
    "joint_imset = ngcasa.imaging.feather(sd_dataset, int_dataset, 'psf')\n",
    "joint_imset = ngcasa.imaging.feather(sd_dataset, int_dataset, 'residual')\n",
    "    \n",
    "# Initialize the mask and iteration control\n",
    "ngcasa.imaging.make_mask(joint_imset,maskpars)\n",
    "iter_rec = ngcasa.imaging.is_converged(joint_imset, iterpars, None)\n",
    "\n",
    "# Perform iterative reconstruction\n",
    "while( iter_rec['stopcode']=='continue' ):\n",
    "    # Minor Cycle\n",
    "    exec_rec = ngcasa.imaging.deconvolve_multiterm(joint_imset, decpars, iter_rec) # MS-Clean or MSMFS\n",
    "\n",
    "    # Copy/transfer the joint model from joint_imset to sd_imset and int_imset\n",
    "    \n",
    "    # Major Cycle for SD\n",
    "    ngcasa.imaging.make_single_dish_residual(sd_imset)\n",
    "    # Make INT Residual image and normalize it\n",
    "    ngcasa.imaging.make_residual_image(int_imset, vis_dataset, gridpars, normpars)\n",
    "    # Feather the SD and INT Cubes together ( PSF and Residual )\n",
    "    joint_imset = ngcasa.imaging.feather(sd_dataset, int_dataset, 'residual')\n",
    "    \n",
    "    # Update the mask and iteration control\n",
    "    ngcasa.imaging.make_mask(joint_imset,maskpars)\n",
    "    iter_rec = ngcasa.imaging.is_converged(joint_imset, iterpars, exec_rec)\n",
    "\n",
    "# Restore the model image\n",
    "ngcasa.imaging.restore_model(joint_imset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkgrwao6Vmdr"
   },
   "source": [
    "### Saving model visibilities\n",
    "\n",
    "Model prediction and saving comes in several flavors. \n",
    "(1) From a component list\n",
    "(2) From a model image\n",
    "(3) uv-cont-fit\n",
    "\n",
    "Model prediction prior to calibration will require the target array to be 'model' whereas simulation will require the target array to be 'data'. ngcasa.imaging.predict_modelvis_xxx() methods take a parameter to specify target array. \n",
    "\n",
    "(1) Calculate visibilities from flux-component lists. They may be observatory calibrator models, or the outputs of an imaging algorithm that produces component lists (e.g. ASP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAARqMA2Vmdu"
   },
   "outputs": [],
   "source": [
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "# Preprocess for freq-frame conversions\n",
    "cngi.vis.regridspw(vis-dataset)  # Convert from topo to lsrk\n",
    "\n",
    "# Predict model visibilities ( in lsrk frame )\n",
    "ngcasa.imaging.predict_modelvis_component(vis_dataset, component_list)\n",
    "\n",
    "# Undo frame conversions\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from lsrk back to data frame (topo)\n",
    "\n",
    "# Write to disk\n",
    "cngi.dio.write_zarr(vis_dataset)\n",
    "    \n",
    "# JW using the storage_parm design makes this unnecessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zESn0vDdVmd4"
   },
   "source": [
    "(2) Calculate visibilities from images, by degridding. The images may be observatory calibrator models or the output of image reconstrunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4swv3R1Vmd-"
   },
   "outputs": [],
   "source": [
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "# Preprocess for freq-frame conversions\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from topo to lsrk\n",
    "\n",
    "# Set up de-grid options for PSterm, Aterm, Wterm, JointMosaic are specified here.\n",
    "ngcasa.imaging.make_gridding_convolution_function(img_dataset, gridpars)\n",
    "\n",
    "# Predict model visibilities ( in lsrk frame )\n",
    "ngcasa.imaging.predict_modelvis_image(vis_dataset, img_dataset)\n",
    "\n",
    "# Undo frame conversions\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from lsrk back to data frame (topo)\n",
    "\n",
    "# Write to disk\n",
    "cngi.dio.write_zarr(vis_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ouUyiF2VmeN"
   },
   "source": [
    "    \n",
    "(3) Baseline-based continuum model fitting ( used in UV-continuum subtraction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRJ_kE3BVmeT"
   },
   "outputs": [],
   "source": [
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "# Preprocess for freq-frame conversions and phase rotation to get the source at the phasecenter\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from topo to lsrk\n",
    "cngi.vis.rotateuvw(vis_dataset)  # Rotate to get source at observatory phase center\n",
    "\n",
    "# Do the uvcontfit : Writes the 'model' array in the XDS vis_dataset\n",
    "cngi.vis.uvcontfit(vis_dataset) # Fit a continuum model per baseline (valid only for a point source at phasecenter)\n",
    "\n",
    "# Undo frame conversions and rotations\n",
    "cngi.vis.rotateuvw(vis_dataset)\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from lsrk back to data frame (topo)\n",
    "\n",
    "# Write to disk\n",
    "cngi.dio.write_zarr(vis_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KW7gYjPVmee"
   },
   "source": [
    "### UV-Continuum Subtraction\n",
    "\n",
    "There are three ways of implementing uv-continuum subtraction. They follow the three options described above for model prediction and saving.  Insert a  cngi.vis.uvsub() step just prior to the final write to zarr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVwFbV1xVmef"
   },
   "outputs": [],
   "source": [
    "## Pick one of the model prediction methods from above.\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from topo to lsrk\n",
    "cngi.vis.rotateuvw(vis_dataset)  # Rotate to get source at observatory phase center\n",
    "cngi.vis.uvcontfit(vis_dataset) # Fit a continuum model per baseline (valid only for a point source at phasecenter)\n",
    "cngi.vis.rotateuvw(vis_dataset)\n",
    "cngi.vis.regridspw(vis_dataset) \n",
    "\n",
    "# Subtract the model from the data. Specify parameters to uvsub to pick which array names to use\n",
    "cngi.vis.uvsub(vis_dataset)\n",
    "\n",
    "# Write to disk\n",
    "cngi.dio.write_zarr(vis_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xi_5aoAMLFJo"
   },
   "source": [
    "### Pointing Self-Calibration\n",
    "\n",
    "Pair a pointing-offset solver from the calibration module \n",
    "with model prediction via A-Projection de-gridding. \n",
    "Incorporate the solve step within the imaging major cycle such that update pointing solutions (in a cal_dataset) are applied during the subsequent residual gridding step. \n",
    "\n",
    "TBD : Check algorithm with listing in publication...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNVhNkdjL-7l"
   },
   "outputs": [],
   "source": [
    "## Major Cycle of image reconstruction, for pointing self-calibration\n",
    "\n",
    "# Set up de-grid options for Aterm with pointing offsets read from a pointing dataset.\n",
    "ngcasa.imaging.make_gridding_convolution_function(img_dataset, gridpars)\n",
    "\n",
    "# Model prediction, using current values from the pointing dataset\n",
    "# This fills in the 'MODEL' array in the vis_dataset\n",
    "ngcasa.imaging.predict_modelvis_image(img_dataset, vis_dataset, pointing_cal_dataset, normpars, gridpars)\n",
    "\n",
    "# Solve for pointing offsets\n",
    "pointing_cal_dataset = ngcasa.calibration.solve_pointing(vis_dataset)\n",
    "\n",
    "# Make residual image and normalize it.\n",
    "ngcasa.imaging.make_residual_image(img_dataset,vis_dataset, pointing_cal_dataset, gridpars,normpars)\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31G5VmJcVmen"
   },
   "source": [
    "## Calibration\n",
    "--------- This section is very preliminary, \n",
    "with only the most basic calibration operations illustrated. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9sU3DDfcHZI"
   },
   "source": [
    "\n",
    "### Calibration API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIIbG9RQVmep"
   },
   "outputs": [],
   "source": [
    "def solve(vis_dataset, solpars):\n",
    "    \"\"\"\n",
    "    Calculate antenna gain solutions according to the parameters in solpars.\n",
    "    The input dataset has been pre-averaged/processed and the model visibilities exist\n",
    "    \n",
    "    Iteratively solve the system of equations g_i g_j* = V_data_ij/V_model_ij  for all ij. \n",
    "    Construct a separate solution for each timestep and channel in the input dataset.\n",
    "    \n",
    "    Options : amp, phase or both\n",
    "              solution type (?) G-term, D-term, etc... \n",
    "              Data array for which to calculate solutions. Default='DATA'\n",
    "              \n",
    "    TBD : Single method with options for solutions of different types ? \n",
    "          Or, separate methods for G/B, D, P etc.. : solve_B, solve_D, solve_B, etc...\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def apply(vis_dataset, [ cal_dataset ], arr_name):\n",
    "    \"\"\"\n",
    "    Apply antenna gain solutions according to the parameters in solpars.\n",
    "    \n",
    "    Calculate  V_ij(corrected) = V_ij(observed) / g_i g_j*\n",
    "    \n",
    "   \n",
    "    Inputs : \n",
    "        List of calibration solution datasets (to apply in the specified order)\n",
    "        Interpolation type ? \n",
    "        Data array on which to operate. Default='DATA'\n",
    "        Data array in which to fill the output.  Default='CORRECTED_DATA'\n",
    "                - this option exists in order to support simulator's corrupt operation where we'd pick 'DATA'\n",
    "    \n",
    "    \n",
    "    TBD : Should this translation of the caltable back to the original un-averaged data be done here, \n",
    "          or in a centralized CNGI method that handles such interpolations for all methods that need\n",
    "          to convert averaged values into un-averaged values.  Note the difference between just copying\n",
    "          and expanding values, versus interpolation. \n",
    "          \n",
    "    TBD : Single apply() method, or several ? \n",
    "    \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrSjIdARVme0"
   },
   "source": [
    "### Calibration Examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9vxxgIvrl3a"
   },
   "source": [
    "#### bandpass + gaincal : \n",
    "Use case : Solve for and applying calibration solutions in a sequence. \n",
    "\n",
    "Step (1) : Predict Model\n",
    "\n",
    "Step (2) Bandpass calibration, where data are averaged across time. Solutions are per channel.\n",
    "\n",
    "Step (3) : Gain calibration, where data are averaged across frequency. Solutions are per time interval\n",
    "\n",
    "Also, include an autoflag step on the gain solutions before applying, in Step (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vApyT7qhVme0"
   },
   "outputs": [],
   "source": [
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "## Step (1) \n",
    "\n",
    "# Predict model visibilities (in lsrk frame) from a component list, and write to the DATA array in the XDS\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from topo to lsrk\n",
    "ngcasa.imaging.predict_modelvis_component(vis_dataset, component_list, arr_name='DATA') # De-grid and predict model\n",
    "cngi.vis.regridspw(vis_dataset)  # Convert from lsrk back to data frame (topo)\n",
    "\n",
    "## Step (2)\n",
    "\n",
    "# Do time-averaging\n",
    "vis_dataset_time_avg = cngi.vis.timeaverage(vis_dataset)\n",
    "\n",
    "# Solve for gains ('solpars' encodes the solution type)\n",
    "cal_dataset_bandpass = ngcasa.calibration.solve(vis_dataset_time_avg, solpars, use_arr_name='data')\n",
    "\n",
    "# <Optionally run autoflag on the gain solutions to take out outliers>\n",
    "# ngcasa.flagging.auto_clip(cal_dataset_bandpass)\n",
    "# cngi.vis.applyflags(cal_dataset_bandpass)\n",
    "\n",
    "# Apply the solutions to the original dataset\n",
    "ngcasa.calibration.apply(vis_dataset, \n",
    "                         cal_dataset_bandpass, \n",
    "                         use_arr_name='data', \n",
    "                         out_arr_name='corrected_data')\n",
    "\n",
    "## Step (3) \n",
    "\n",
    "# Do chan-averaging on original dataset\n",
    "vis_dataset_chan_avg = cngi.vis.chanaverage(vis_dataset)\n",
    "\n",
    "# Solve for gains ('solpars' encodes the solution type)\n",
    "cal_dataset_gaincal = ngcasa.calibration.solve(vis_dataset_chan_avg, solpars, use_arr_name='corrected_data')\n",
    "\n",
    "# Apply the solutions to the pre-calibrated dataset. Note the change in arr_name. \n",
    "ngcasa.calibration.apply(vis_dataset, \n",
    "                         cal_dataset_gaincal, \n",
    "                         use_arr_name='corrected_data', \n",
    "                         out_arr_name='corrected_data')\n",
    "\n",
    "## OR..... Re-apply all the solutions to the original data...\n",
    "#ngcasa.calibration.apply(vis_dataset, \n",
    "#                         [cal_dataset_bandpass, cal_dataset_gaincal], \n",
    "#                         use_arr_name='data',\n",
    "#                         out_arr_name='corrected_data')\n",
    "\n",
    "# Save calibrated data to disk\n",
    "cngi.write_zarr(vis_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsQXIQh7Vme7"
   },
   "source": [
    "#### Solutions requiring pre-apply of upstream solutions\n",
    "\n",
    "Example : Pre-apply a pre-existing bandpass solution before averaging (to the MODEL data) and solve for time-varying gains. \n",
    "\n",
    "TBD : Do we need this mode of operation ? \n",
    "\n",
    "-- Since calibration solutions are obtained from a point source model (i.e. data / model ), the multiplication of g_i g_j\\*  with Model visibilities is the same as dividing g_i g_j\\* out of the Data visibilities.\n",
    "\n",
    "-- Therefore, will the above solution (of applying solutions to the data and corrected_data column in a sequence) suffice ? Note that nothing is written to disk after each apply, but only written once at the very end.\n",
    "\n",
    "TBD : If this doesn't cover all use cases, and we need an explicit pre-apply, need to define  ngcasa.calibration.pre_apply() to multiply 'MODEL' data with g_i g_j* from a list of input cal_datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4L996opxVme_"
   },
   "source": [
    "#### Polarization calibration (TBD)\n",
    "TBD : Add example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQ2HVIc9VmfB"
   },
   "source": [
    "## Flagging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njpmutg-cMM2"
   },
   "source": [
    "\n",
    "### Flagging API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rH2m0yBPVmfG"
   },
   "outputs": [],
   "source": [
    "def manual_flag(vis_dataset, selpars):\n",
    "    \"\"\"\n",
    "    Define a set of data selection queries to mark as flags.\n",
    "    \n",
    "    For each query in the input list, set flag=1 for the intersection of \n",
    "    selections along multiple dimensions.\n",
    "    \n",
    "    Inputs : \n",
    "        (1) list of selection queries\n",
    "        (2) array name for output flags. Default = FLAG\n",
    "        \n",
    "    TBD : How to implement this ? Just a series of vis_dataset.isel(...) calls in sequence ?\n",
    "        What magic does the framework provide to make this efficient for the several 1000s \n",
    "        of selections that are typical for online flags. \n",
    "       \n",
    "       list_sels : [{'time':[76,77,78], 'chan':[6,7,8,12]},\n",
    "           {'time':[112,113], 'chan':[6,7,56]}]\n",
    "       \n",
    "       for sel in list_sels : \n",
    "           new_xds = vis_dataset.isel(**sel)\n",
    "           new_xds.FLAG = 1   ( or equivalent )\n",
    "           <save them to original vis_dataset ? >\n",
    "           \n",
    "           \n",
    "    Other ideas : \n",
    "    -- xarray.ones_like(xds.DATA).where(<some conditions>, other=0)\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "def manual_unflag(vis_dataset, selpars):\n",
    "    \"\"\"\n",
    "    Define a set of data selection queries to mark as flags.\n",
    "    \n",
    "    Inputs : \n",
    "        (1) list of selection queries\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "    \"\"\"\n",
    "\n",
    "def shadow(vis_dataset, shadowlimit):\n",
    "    \"\"\"\n",
    "    Flag all baselines for antennas that are shadowed beyond the specified tolerance. \n",
    "    \n",
    "    All antennas in the zarr-file metadata (and their corresponding diameters) \n",
    "    will be considered for shadow-flag calculations. \n",
    "    For a given timestep, an antenna is flagged if any of its baselines\n",
    "    (projected onto the uv-plane) is shorter than  radius_1 + radius_2 - tolerance.\n",
    "    The value of 'w' is used to determine which antenna is behind the other.\n",
    "    The phase-reference center is used for antenna-pointing direction.\n",
    "    \n",
    "    Antennas that are not part of the observation, but still physically\n",
    "    present and shadowing other antennas that are being used, must be added\n",
    "    to the meta-data list in the zarr prior to calling this method. \n",
    "    \n",
    "    Inputs : \n",
    "        (1) shadowlimit or tolerance (in m)\n",
    "        (2) array name for output flags. Default = FLAG  \n",
    "    \"\"\"\n",
    "\n",
    "def elevation(vis_dataset):\n",
    "    \"\"\"\n",
    "    Flag data for low elevations\n",
    "    \n",
    "    Inputs : \n",
    "        (1) tolerance\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "    \"\"\"\n",
    "    \n",
    "def quack(vis_dataset):\n",
    "    \"\"\"   \n",
    "    TBD : Change name ?!! \n",
    "    \n",
    "    Flag the beginning and/or end of scans to account for observation effects\n",
    "    such as antenna slewing delays. \n",
    "    \n",
    "    Inputs : \n",
    "        (1) time-width, beginning or end or both\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def auto_clip(vis_dataset):\n",
    "    \"\"\"\n",
    "    An autoflag algorithm that clips the result of a specified expression.\n",
    "\n",
    "    Inputs : \n",
    "        (1) algo parameters\n",
    "        (2) array name for output flags. Default = FLAG   \n",
    "        (3) array name for input flags. Default = FLAG    \n",
    "\n",
    "    If a new flag_array is picked for the output, save only 'new' flags.\n",
    "    They can be merged with pre-existing flags in a separate step\n",
    "    \n",
    "    If an existing flag_array is picked for the output, merge with logical OR.\n",
    "    \"\"\"\n",
    "def auto_rflag(vis_dataset):\n",
    "    \"\"\"\n",
    "    An autoflag algorithm that detects outliers via hierarchical MAD statistics\n",
    "    applied to the visibility data. \n",
    "    \n",
    "    Inputs : \n",
    "        (1) algo parameters\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "        (3) array name for input flags. Default = FLAG   \n",
    "\n",
    "    If a new flag_array is picked for the output, save only 'new' flags.\n",
    "    They can be merged with pre-existing flags in a separate step\n",
    "    \n",
    "    If an existing flag_array is picked for the output, merge with logical OR.\n",
    "    \"\"\"\n",
    "def auto_tfcrop(vis_dataset):\n",
    "    \"\"\"\n",
    "    An autoflag algorithm that detects outliers based on the assumption that the\n",
    "    time-frequency plane of the visibilities for a sky signal is smooth in comparison to RFI.\n",
    "    \n",
    "    Inputs : \n",
    "        (1) algo parameters\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "        (3) array name for input flags. Default = FLAG\n",
    "    \n",
    "    If a new flag_array is picked for the output, save only 'new' flags.\n",
    "    They can be merged with pre-existing flags in a separate step\n",
    "    \n",
    "    If an existing flag_array is picked for the output, merge with logical OR.\n",
    "    \"\"\"\n",
    "    \n",
    "def auto_uvbin(vis_dataset):\n",
    "    \"\"\"\n",
    "    An autoflag algorithm that detects outliers on the gridded spatial frequency plane\n",
    "    (Algorithm prototype exists).\n",
    "    \n",
    "    TBD : How can this method call  ngcasa.imaging._make_grid() and also satisfy code structure rules ?\n",
    "    \n",
    "    Inputs : \n",
    "        (1) algo parameters\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "        (3) array name for input flags. Default = FLAG\n",
    "    \n",
    "    If a new flag_array is picked for the output, save only 'new' flags.\n",
    "    They can be merged with pre-existing flags in a separate step\n",
    "    \n",
    "    If an existing flag_array is picked for the output, merge with logical OR.\n",
    "    \"\"\"\n",
    "\n",
    "def extend(vis_dataset): \n",
    "    \"\"\"\n",
    "    Extend and grow existing flags.\n",
    "    \n",
    "    Options : grow-around, extendflags, growtime, growfreq, antint.. etc....\n",
    "    \n",
    "    Inputs : \n",
    "        (1) algo parameters\n",
    "        (2) array name for output flags. Default = FLAG    \n",
    "        (3) array name for input flags. Default = FLAG\n",
    "        \n",
    "    If a new flag_array is picked for the output, save only 'new' flags.\n",
    "    They can be merged with pre-existing flags in a separate step\n",
    "    \n",
    "    If an existing flag_array is picked for the output, merge with logical OR.\n",
    "    \"\"\"\n",
    "    \n",
    "def summary(vis_dataset):\n",
    "    \"\"\"\n",
    "    Return a dictionary containing metrics to assess flagging quality\n",
    "    \n",
    "    Type 1 : Flag counts\n",
    "\n",
    "    Flag ratio = n_flags/n_total along multiple axes and different levels of granularity.\n",
    "    \n",
    "    \n",
    "    Type 2 : Flag validity \n",
    "    \n",
    "    Compare statistics of flagged versus unflagged visibility data\n",
    "    and define a metric that quantifies the following.\n",
    "     \n",
    "      - Flagged data must have a higher mean than unflagged data\n",
    "      - Unflagged data should follow Gaussian stats\n",
    "      - Protect against under-flagging (less than 10%) or over-flagging (more than 70%)\n",
    "\n",
    "    This option is for pipelines or applications that need to auto-tune autoflag parameters\n",
    "    (An 'autotune' algorithm prototype exists). \n",
    "\n",
    "    Example (this is very rudimentary) : \n",
    "    score1 = (mean(flagged_data) - mean(unflagged_data))/mean(unflagged_data)\n",
    "    score2 = ( max(unflagged_data)/ mean(unflagged_data) - 3.0 )\n",
    "    score3 = (count(flagged)/count(total) - 0.1)*2 +  (count(flagged)/count(total) - 0.7)*2\n",
    "\n",
    "\n",
    "    Inputs : \n",
    "        (1) list of metrics to evaluate and return\n",
    "        (2) array name for input flags. Default = FLAG    \n",
    "\n",
    "    \"\"\"\n",
    "# JW The summary can be returned as part of the vis_dataset.\n",
    "def manage_flags(vis_dataset, in_flags=[], out_flag=''):\n",
    "    \"\"\"\n",
    "    A flag manager that applies Boolean logic operators to \n",
    "    - merge multiple flag versions into one.   \n",
    "    - delete flag versions\n",
    "    - list existing version names\n",
    "    \n",
    "    Inputs : \n",
    "        (1) List of input flag array names\n",
    "        (2) array name for output flags. Default = FLAG\n",
    "        (3) Operation (AND, OR)  TBD : supply the expression, instead of canned options. \n",
    "    \n",
    "    If an existing flag array is named as the output, the contents are over-written.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFWa_LSSVmfM"
   },
   "source": [
    "### Flagging Examples\n",
    "\n",
    "Flags are stored as Boolean arrays in the zarr and xarray datasets. \n",
    "\n",
    "Flag versions are maintained by giving these arrays names. Each flagging method can write to a specified named flag array. \n",
    "\n",
    "Applications that use flags will read from the specified flag array name and set corresponding data array values to NaN (using cngi.vis.applyflags()) before proceeding.\n",
    "See : https://cngi-prototype.readthedocs.io/en/latest/visibilities.html#Flagging\n",
    "\n",
    "Interactive flag visualization may be done at the application layer by inserting a plotting/visualization step in between any of the calls to ngcasa.flagging methods. Flag versions may be managed (merged, copied, deleted) using the ngcasa.flagging.manage_flags() method. For the inevitable experimentation required to tune autoflag parameters, a named flag array may be created, used, visualized, and then discarded. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5JEWtquriK8"
   },
   "source": [
    "#### Manual and meta-data based flags\n",
    "Online flags typically consist of many (1000s) of data selection queries that mark regions to be flagged. \n",
    "\n",
    "Shadow and elevation flagging is also typically done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ivy2KnNBVmfN"
   },
   "outputs": [],
   "source": [
    "#Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "#Define manual flags using the 'isel' syntax that references keywords in the zarr/xds\n",
    "# https://cngi-prototype.readthedocs.io/en/latest/visibilities.html#Selection-and-Splitting\n",
    "\n",
    "list_sels = [{'time':[76,77,78], 'chan':[6,7,8,12]},\n",
    "             {'time':[112,113], 'chan':[6,7,56]}]\n",
    "\n",
    "# Set the FLAG to 1 for all points in the union of all selections\n",
    "ngcasa.flagging.manual_flag(vis_dataset,list_sels, flag_name='FLAG')\n",
    "\n",
    "# Calculate shadow and elevation flags\n",
    "ngcasa.flagging.elevation(vis_dataset)\n",
    "ngcasa.flagging.shadow(vis_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1y9ZQIqVmfS"
   },
   "source": [
    "#### Autoflag with extension and pre-existing flags\n",
    "This example demonstrates the use-case of extending flags generated only by\n",
    "the autoflag algorithm, but not all manually-set pre-existing flags. \n",
    "\n",
    "This is a use-case currently not possible in the casa6 flagger framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17z-l2saVmfT"
   },
   "outputs": [],
   "source": [
    "#Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "# Do some manual flagging and save the flags to the FLAG column. \n",
    "ngcasa.flagging.manual_flag(vis_dataset, list_sels, out_flag_name='FLAG')\n",
    "\n",
    "# Run the rflag algorithm using FLAG as the pre-existing flags,\n",
    "# Write only the new flags into a new FLAG_AUTO array.\n",
    "ngcasa.flagging.auto_rflag(vis_dataset_avg,algopars,\n",
    "                           in_flag_name='FLAG',\n",
    "                           out_flag_name='FLAG_AUTO')\n",
    "\n",
    "# Extend only the new autoflags, but not all pre-existing flags\n",
    "ngcasa.flagging.extend(vis_dataset,extendpars, \n",
    "                    in_flag_name='FLAG_AUTO',\n",
    "                    out_flag_name='FLAG_AUTO')\n",
    "\n",
    "# Now, merge the flags using a logical OR, and save it into the default 'FLAG' array\n",
    "ngcasa.flagging.manage_flags(vis_dataset,\n",
    "                             in_flags=['FLAG','FLAG_AUTO'], \n",
    "                             out_flag_name='FLAG', \n",
    "                             op='or')\n",
    "\n",
    "## < Visualize the flags by plotting the data with a chosen flagversion > \n",
    "## < If unsatified, discard flagversion using a cngi.dio.xxxx step and repeat the above >\n",
    "\n",
    "## Save vis_dataset to zarr.\n",
    "cngi.dio.write_zarr(vis_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mlQHulcVmfY"
   },
   "source": [
    "#### Autoflag with pre-averaging\n",
    "This example demonstrates averaging for autoflagging, expanding the flags back to the original dataset. Two manual flag calls are also included, one on the original data and one after averaging.\n",
    "\n",
    "Flag expansion is done as a regrid operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAOOj_dYVmfY"
   },
   "outputs": [],
   "source": [
    "# Construct a selected vis dataset\n",
    "vis_dataset = cngi.dio.read_vis(visname, selpars)\n",
    "\n",
    "# (1) Do some manual flagging and save the flags to the FLAG column. \n",
    "ngcasa.flagging.manual_flag(vis_dataset, list_sels_original, out_flag_name='FLAG')\n",
    "\n",
    "# Now, average the data in both time and frequency prior to running autoflag.\n",
    "vis_dataset_time_avg = cngi.vis.timeaverage(vis_dataset)\n",
    "vis_dataset_time_freq_avg = cngi.vis.chanaverage(vis_dataset_time_avg)\n",
    "\n",
    "# (2) Run the tfcrop algorithm using FLAG as the pre-existing flags\n",
    "# and save the new flags into the same flag array.\n",
    "ngcasa.flagging.auto_tfcrop(vis_dataset_time_freq_avg,algopars,\n",
    "                           in_flag_name='FLAG',\n",
    "                           out_flag_name='FLAG')\n",
    "\n",
    "# (3) Manual flags, using meta-data corresponding to the averaged-data.\n",
    "ngcasa.flagging.manual_flag(vis_dataset_time_freq_avg, list_sels_lowres, out_flag_name='FLAG')\n",
    "\n",
    "# (4) Manual unflag, using meta-data corresponding to the averaged-data\n",
    "ngcasa.flagging.manual_unflag(vis_dataset_time_freq, list_sels_lowres_unflag, out_flag_name='FLAG')\n",
    "\n",
    "\n",
    "# Now, expand the flags back to the original resolution. \n",
    "#        Note that Step (1) was already on the original data. \n",
    "#        The results of Steps (2) and (3) and (4) will get expanded out. \n",
    "#\n",
    "## TBD : Need a demo at the CNGI level of how to expand flags back to the original data\n",
    "##       Expansion is a regrid where the same value is repeated across the expanded range.\n",
    "cngi.vis.regrid(in_xds=vis_dataset_time_freq, out_xds=vis_dataset)\n",
    "\n",
    "# Save to disk\n",
    "cngi.dio.write_zarr(vis_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLOHq6YKVmfo"
   },
   "source": [
    "#### FlagVersion handling for pipelines\n",
    "Save and restore flag versions, along with dataset selections/splits.\n",
    "\n",
    "The use case is based on current operations with casa6, where parallelization is implemented by partitioning the data and running operations that set flags, on each subset.  It is TBD whether this use-case is still relevant with CNGI and ngCASA, but here is an example to showcase how this may be achieved. \n",
    "\n",
    "TBD : Need input from pipeline group : Does this represent a relevant use case ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jP2-C1saVmfp"
   },
   "outputs": [],
   "source": [
    "#Construct several selected vis datasets\n",
    "vis_dataset_target1 = cngi.dio.read_vis(visname, selpars_target1)\n",
    "vis_dataset_target2 = cngi.dio.read_vis(visname, selpars_target2)\n",
    "\n",
    "# Do different operations on the two datasets\n",
    "cngi.ngcasa.autoflag_rflag(vis_dataset_target1)\n",
    "cngi.ngcasa.manual_flag(vis_dataset_target2,list_sels_to_flag)\n",
    "\n",
    "# Regrid/expand the flags back to the original dataset\n",
    "cngi.vis.regrid(in_xds=vis_dataset_target1, out_xds=vis_dataset)\n",
    "cngi.vis.regrid(in_xds=vis_dataset_target2, out_xds=vis_dataset)\n",
    "\n",
    "# Save to disk\n",
    "cngi.dio.write_zarr(vis_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsgQ1KfxVmgF"
   },
   "source": [
    "## Simulation\n",
    "Make the MS frame. Calculate all the meta-data and coordinates. \n",
    "Use the calibrator and imager modules for the data prediction and corruption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwfelVt_VmgG"
   },
   "source": [
    "### Simulation API\n",
    "Move the API entirely into CNGI ? \n",
    "\n",
    "Note : The API definition should mostly follow the casa6.casatools.simulator interface, except for the steps of calculating visibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gw_RBmltVmgI"
   },
   "outputs": [],
   "source": [
    "def add_meta_data():\n",
    "    \"\"\"\n",
    "    Make an empty dataset, or append to an existing vis_dataset.\n",
    "    Each call to this method will construct meta-data (UVW values, time values, etc) for one scan/spw_pol/field. \n",
    "    \n",
    "    A dataset containing multiple scans, fields(pointings) or spectral window and pol settings may be \n",
    "    constructed by calling this method in a sequence. \n",
    "    \n",
    "    Inputs : \n",
    "        - Observation phase center\n",
    "        - Spectral window and polarization setup parameters (chanwidth, nchan, startchan, etc...)\n",
    "        - Array configuration\n",
    "        - Integration length and Time-range of one scan.\n",
    "\n",
    "    Output : \n",
    "        - A new or appended XDS with new/appended meta-data information\n",
    "\n",
    "    TBD : Split this into smaller methods as needed. \n",
    "        Can follow the casa6.casatools.simulator tool interface for all methods required before the actual calculation of visibility values.    \n",
    "        May be best to make them simulation_utils methods though. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "def add_noise():\n",
    "    \"\"\"\n",
    "    Add noise to the DATA column of the MS\n",
    "    \n",
    "    Options : \n",
    "     - Gaussian random noise of specified standard-deviation\n",
    "     - Noise that accounts for delta-T and delta-NU of the observation. \n",
    "     - Noise that accounts for different antenna collecting areas (from dish diameter meta-data)\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wieqd2KeVmgN"
   },
   "source": [
    "### Simulation examples\n",
    "Simulation is an application that uses the simulator, calibrator, flagger and imager modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZqYHajGrcz3"
   },
   "source": [
    "#### Simulate a wideband mosaic observation with a heterogenous array.\n",
    "This is an ngVLA and ALMA use-case. \n",
    "\n",
    "- Call the simulator methods in a sequence to generate an empty dataset containing only coordinates and metadata\n",
    "- Call flagger methods to flag shadowed or low-elevation data\n",
    "- Call imager methods to predict visibilities\n",
    "- Call calibrator methods to corrupt the data\n",
    "\n",
    "Assumption : A true-sky model image already exists in img_dataset. A cal_dataset also exist (to apply gain errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3RzTM5gVmgO"
   },
   "outputs": [],
   "source": [
    "# List of mosaic pointings\n",
    "list_fields=[{'ra1':'xxxx', 'dec1':'xxxx'},\n",
    "             {'ra2':'xxxx', 'dec2':'xxxx'}]\n",
    "# List of spectral windows with pol specs\n",
    "list_spws=[{'start':'1GHz','nchan':100, 'width'='10MHz', 'pol'='RR,LL'},\n",
    "           {'start':'2GHz','nchan':1000, 'width'='1MHz', 'pol'='RR,LL'}]\n",
    "# List of scans\n",
    "list_scans=[{'date':'xxx', 'ha_start':'-4h', 'ha_stop':'-3h', 'integration'='1s'},\n",
    "            {'date':'xxx', 'ha_start':'-2h', 'ha_stop':'-1h', 'integration'='1s'} ]\n",
    "\n",
    "# Construct meta-data for the observation.\n",
    "sim_dataset = None\n",
    "for scan in scans:\n",
    "    for field in fields:\n",
    "        for spw in spws:\n",
    "            sim_dataset = ngcasa.simulation.add_meta_data(sim_dataset, scan, field, spw)\n",
    "\n",
    "# Flag data for low elevation or shadows\n",
    "ngcasa.flagging.shadow(sim_dataset)\n",
    "ngcasa.flagging.elevation(sim_dataset)\n",
    "\n",
    "# Predict model visibilities (in lsrk frame) from an image, and write to the DATA array in the XDS\n",
    "cngi.vis.regridspw(sim_dataset)  # Convert from topo to lsrk\n",
    "ngcasa.imaging.make_gridding_convolution_function(img_dataset, gridpars) # Setup de-gridding (include het-array PBs)\n",
    "ngcasa.imaging.predict_modelvis_image(sim_dataset, component_list, arr_name='DATA') # De-grid and predict model\n",
    "cngi.vis.regridspw(sim_dataset)  # Convert from lsrk back to data frame (topo)\n",
    "\n",
    "# Corrupt by antenna gains \n",
    "ngcasa.calibration.apply(sim_dataset, cal_dataset_corrupt, use_arr_name='DATA', out_arr_name='DATA')\n",
    "\n",
    "# Add Gaussian random noise\n",
    "ngcasa.simulation.add_noise(sim_dataset)\n",
    "\n",
    "# Save to disk\n",
    "cngi.write_zarr(sim_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wglscWfyVmbw"
   },
   "source": [
    "# Questions for CNGI/ngCASA team discussion : \n",
    "\n",
    "(1)  Are img_datasets expected to contain one image at a time, or entire sets used for imaging ? \n",
    "    - Some methods need to see sets of associated images, whereas others need just one image.\n",
    "    - Some methods change the shape of the image, but it is still associated with the same reconstruction run\n",
    "    ==> It seems best to restrict an img_dataset to contain only one image array. \n",
    "    \n",
    "    Example : Cube vs MFS have different image definitions. \n",
    "    For mtmfs, major cycles are cubes, and minor cycles are MTMFS. \n",
    "    So here, should both definitions reside inside the same img_dataset \n",
    "    and the deconvolver know to look for some naming convention ?  \n",
    "    How to do this cleaner ? \n",
    "    \n",
    "    # JW I think img_dataset can contain any number of images (same for vis_datasets and data). The user should just tell the ngcasa function what image to use (see ngcasa.imaging.make_image api).\n",
    "    \n",
    "(2) How to reconcile the 'stateless function' approach with the need for maintaining iteration control state right through an image reconstruction run ? => The application layer will have to manage return-vals, inp_vals and 'state' ?\n",
    "\n",
    "    # JW States can be attached in the attribute section of the relevant dataset.\n",
    "\n",
    "(3) When to use parameters to a single method, versus having multiple methods ?  The former allows for cleaner application code. The latter allows for more atomic code structure.  => Decide on a case-by-case basis ? \n",
    "\n",
    "    # JW It should be a balance (case-by-case basis). I think the functions you suggested achieve that. \n",
    "\n",
    "(4) Are there rules for what data-array names are allowed in the XDS and Zarr datasets ? Can we implement 'versioning' of arrays simply by picking different names ? E.g. Versions of corrected_data or flags. This is something in the MS V3 that we have needed for a long time.    All the above usage examples assume this is possible. \n",
    "    \n",
    "    # JW Any name should be allowed with defaults.\n",
    "\n",
    "(5) Need more examples in CNGI\n",
    "\n",
    "- Example of how to merge img_datasets that may have different image shapes ?  Join operation for xds\n",
    "  - Needed for linear_mosaic, merge_models_across_image_fields...\n",
    "  \n",
    "        #JW Maybe a cngi_function should do this.\n",
    "  \n",
    "- Example of how to merge vis_Datasets ? Join operation for xds\n",
    "  - Needed for pipeline use case of doing different operations on different subsets of the data, and then joining the results.  A simple 'regrid' call ? \n",
    "  \n",
    "        #JW Not sure.\n",
    "  \n",
    "- MS-Selection replacement examples : How to connect the zarr and xarray metadata to selection data\n",
    "\n",
    "       #JW Selection should be done using isel etc. There are examples in cngi.\n",
    "\n",
    "- ComponentList replacement examples : Just a dictionary that we have to define and decide upon ?\n",
    "\n",
    "        #JW Yes\n",
    "\n",
    "- Reverse operation for time/chan average or rebin/regrid, or topo-lsrk. \n",
    "  E.g. vis.timeaverage () followed by 'edit flags' and then write back to original dataset ? FLAG value is to be copied during expansion. \n",
    "  E.g. Caltable solutions need an interpolation to get back to the original data resolution. Interpolation+Extrapolation\n",
    "  E.g. vis.chanaverage() followed by 'edit CORRECTED_DATA' (e.g. uvcontfit+uvsub), and then write back to original dataset. This makes no sense. So, how to prevent this ?\n",
    "\n",
    "\n",
    "- Visualization ? \n",
    "  - Point to available python libs for data visualization...\n",
    "  - With array 'versioning' implemented as separate arrays... it's easy to plot/explore versions. On-the-fly application of operations (averaging, coord-shifts, cal-apply, model-predict) is also possible simply by not saving to disk before visualization. \n",
    "  - It can be inserted between any sequence of steps in any user application script.\n",
    "  - Will apply to vis and cal datasets, and img datasets too. This will get us scatter and raster displays for all kinds of datasets...\n",
    "  \n",
    "      \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ngCASA_Application_Examples.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
