{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scU9JVUodThH"
   },
   "source": [
    "# Development\n",
    "\n",
    "[edit this notebook in colab](https://colab.research.google.com/github/casangi/ngcasa/blob/master/docs/ngcasa_development.ipynb)\n",
    "\n",
    "The proposed plan for radio astronomy data reduction software consists out of three layers:\n",
    "- Application Software\n",
    "- ngCASA functions\n",
    "- CNGI functions\n",
    "\n",
    "The application software layer is what ultimately most astronomers will use. This document describes the building blocks that may be assembled to create the application software. Consequently, ngCASA and CNGI is aimed at the following users:\n",
    "\n",
    "- CASA Developers\n",
    "- Pipeline Developers\n",
    "- Advance users and algorithm developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ngCASA Prototype\n",
    "\n",
    "The following ngCASA functions have working prototypes:\n",
    "- [make_imaging_weight](https://ngcasa.readthedocs.io/en/latest/_api/api/ngcasa.imaging.make_imaging_weight.html#ngcasa.imaging.make_imaging_weight)\n",
    "- [make_psf](https://ngcasa.readthedocs.io/en/latest/_api/api/ngcasa.imaging.make_psf.html#ngcasa.imaging.make_psf)\n",
    "- [make_image](https://ngcasa.readthedocs.io/en/latest/_api/api/ngcasa.imaging.make_image.html#ngcasa.imaging.make_image)\n",
    "\n",
    "Example notebooks can be found [here](https://ngcasa.readthedocs.io/en/latest/prototypes.html). In the [continuum imaging](https://ngcasa.readthedocs.io/en/latest/prototypes/continuum_imaging_example.html) and [cube imaging](https://ngcasa.readthedocs.io/en/latest/prototypes/cube_imaging_example.html)  example notebooks the images generated by the ngCASA prototype and CASA are compared. A benchmarking comparison between the ngCASA prototype and CASA can be found [here](https://ngcasa.readthedocs.io/en/latest/benchmark.html).\n",
    "\n",
    "### Chunking\n",
    "\n",
    "In the zarr and dask model, data is broken up into chunks. The chunk size can be specified in the ```xarray.open_zarr``` call using the ```chunks``` parameter. The dask and zarr chunking do not have to be the same. The [zarr chunking](https://zarr.readthedocs.io/en/stable/tutorial.html) is what is used on disk and the [dask chunking ](https://docs.dask.org/en/latest/array-chunks.html) is used during parallel computation. However, it is more efficient for the dask chunk size to be equal to or a multiple of the zarr chunk size (to stop multiple reads of the same data). This hierarchy of chunking allows for flexible and efficient algorithm development. For example cube imaging is more memory efficient if chunking is along the channel axis (the [benchmarking](https://ngcasa.readthedocs.io/en/latest/benchmark.html) example demonstrates this). Note, chunking can be done in any combination of dimensions.\n",
    "\n",
    " When using different chunking than the chunking on disk the ```overwrite_encoded_chunks``` parameter in the  ```xarray.open_zarr``` call should be set to True. The ```storage_parms['chunks_on_disk']``` and ```storage_parms['chunks_return']``` functionality is still experimental, please report any bugs. There should also be no dask chunking on the polarization dimension.\n",
    "\n",
    "\n",
    "### ngCASA Function Template\n",
    "```python\n",
    "def ngcasa_func(dataset_1, ..., dataset_n, parms_1, ..., parms_m, storage_parms):\n",
    "    \"\"\"\n",
    "    Description of function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_1 : xarray.core.dataset.Dataset\n",
    "    ...\n",
    "    dataset_n : xarray.core.dataset.Dataset\n",
    "    parms_1 : dict\n",
    "    ...\n",
    "    parms_m : dict\n",
    "    storage_parms : dictionary\n",
    "    storage_parms['to_disk'] : bool, default = False\n",
    "    storage_parms['append'] : bool, default = False\n",
    "    storage_parms['outfile'] : str\n",
    "    storage_parms['chunks_on_disk'] : dict of int, default ={}\n",
    "    storage_parms['chunks_return'] : dict of int, default = {}\n",
    "    storage_parms['graph_name'] : str\n",
    "    storage_parms['compressor'] : numcodecs.blosc.Blosc,default=Blosc(cname='zstd', clevel=2, shuffle=0)\n",
    "    Returns\n",
    "    -------\n",
    "    output_dataset_1 : xarray.core.dataset.Dataset\n",
    "    ...\n",
    "    output_dataset_k : xarray.core.dataset.Dataset\n",
    "    \"\"\"\n",
    "```\n",
    "ngCASA functions will receive and return xarray datasets. By default calling an ngCASA function will not do computation, but rather build a graph of the computation ([example of a graph](https://ngcasa.readthedocs.io/en/latest/prototypes/cube_imaging_example.html)). Computation can be triggered by using ```dask.compute(dataset)```. Each ngCASA function will also have the ```storage_parms``` input, by default ```storage_parms['to_disk']``` is set to False and the other dictionary elements have no effect. However, if ```storage_parms['to_disk']``` is True a compute is triggered and data is written to disk, [example of using storage_parms](https://ngcasa.readthedocs.io/en/latest/prototypes/imaging_weights_example.html). The ```storage_parms['to_disk']``` elements have the following functionality:\n",
    "\n",
    "- ```storage_parms['to_disk']``` If True the dask graph is executed and saved to disk in the zarr format.\n",
    "- ```storage_parms['append']```  If ```storage_parms[‘to_disk’]``` is True only the dask graph associated with the function is executed and the resulting data variables are saved to an existing zarr file on disk. Note that graphs of unrelated data to this function will not be executed or saved. The append function also only works for data variables whose dimensions are already part of the dataset on disk.\n",
    "- ```storage_parms['outfile']``` The zarr file to create or append to.\n",
    "- ```storage_parms['chunks_on_disk']``` The chunk size to use when writing to disk. This is ignored if ```storage_parms['append']``` is True.\n",
    "- ```storage_parms['chunks_return']``` The chunk size of the dataset that is returned. \n",
    "- ```storage_parms['graph_name']``` The time to compute and save the data is stored in the attribute section of the dataset and ```storage_parms['graph_name']``` is used in the label.\n",
    "- ```storage_parms['compressor']``` The compression algorithm to use. Available compression algorithms can be found [here](https://numcodecs.readthedocs.io/en/stable/blosc.html).\n",
    "\n",
    "The data variables in the dataset that the function uses to build the graph can be specified by the user. There will, however, be defaults for example the [make_image](https://ngcasa.readthedocs.io/en/latest/_api/api/ngcasa.imaging.make_image.html#ngcasa.imaging.make_image) function has the ```user_grid_parms['data_name']``` parameter. This parameter sets the name of the data variable that contains the visibilities to be gridded and the default is 'DATA'. In the [imaging weight example notebook](https://ngcasa.readthedocs.io/en/latest/prototypes/imaging_weights_example.html) this functionality is demonstrated. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ys3IrmPfZN99"
   },
   "source": [
    "## Future Design Decisions\n",
    "\n",
    "### Data Structures \n",
    "The initial exercise of defining an ngCASA API and writing example usage scripts raised the following questions related to default data structures that CNGI and ngCASA will adopt.\n",
    "\n",
    "### Visibilities zarr/xarray\n",
    "A default list of array names is as defined in CNGI. But, to get the ability to have versions of arrays, any application may add arrays as needed. Examples are corrected_data_1, corrected_data_2, flag_original, flag_auto, etc. All additional arrays must conform to the same meta-data and coordinates. But now, all methods (even CNGI) need the ability to specify an array name to use, with the default being from the core definition. \n",
    "\n",
    "### Image zarr/xarray\n",
    "What is the default list of array names (i.e. image products) to store? The current specification in CNGI is tied closely to the casa6 tclean's list of outputs. However, not every applications/users will need this full list. Therefore, we perhaps should require that an image dataset contain a minimum of 1 array with a predefined default name, but then allow the appending of more. All image arrays within a set must share the same shape and coordinate metadata. Here too, all methods (even CNGI) that operate on images must have the ability to specify an array name to use. \n",
    "\n",
    "### A Caltable\n",
    "Need to define the default structure of a zarr/xarray dataset meant to store calibration solutions. Same requirements from above apply here too.\n",
    "\n",
    "### Primary Beam models Convolution Function Cache\n",
    "We need a persistent data structure to store and use gridding convolution functions. The imaging prototype is developing one, related to the casa6 CFCache. A mechanism to convert between a Primary-Beam model database and a convolution function cache must also be designed. \n",
    "\n",
    "### Flux Component List\n",
    "We need a definition of a component list as an alternative to a raster image. This is required for compatibility with catalogues and translation between sky models that are not fitted/evaluated on a pixellated grid. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2E0Zv4CCalJ"
   },
   "source": [
    "## List of Future Prototypes\n",
    "The following are suggestions to add to the list of CNGI and ngCASA prototypes that demonstrate that algorithms and science use cases can be implemented with minimal complexity and that they scale as expected. \n",
    "\n",
    "Note : This list is preliminary in content, and has no fixed timelines associated with it. \n",
    "\n",
    "### Join Operation\n",
    "\n",
    "Demonstrate a join operation for zarr/xds datasets for visibilities, images, caltables, CF-caches, etc. \n",
    "\n",
    "- Visibilities : A common use case is to combine data from multiple datasets that may not share meta-data or be consistent in shape. Some algorithms must be done on each dataset (or subset) separately, whereas others are to be done on an entire set.   \n",
    "    - Option1 : Always work with small homogeneous subsets of data and have the application layer manage lists and merging of products (via loops). \n",
    "    - Option2 : Implement a join and then use data selection as needed. All applications then strictly can take single datasets as inputs. Algorithms such as imaging can view it as a single large dataset. However, for some algorithms (such as calibration solutions that must pay attention to different meta-data across subsets) the internal diversity will still have to be managed through loops inside the methods.\n",
    " \n",
    "  Current CASA6 has a mix of both the following and this is a significant source of inconsistency. Can the new framework simplify any book-keeping for this use-case without sacrificing other aspects such as performance ? \n",
    "\n",
    "- Images : Applications may need to work with multiple image sets that may not share the same shape or meta-data. \n",
    "  - Should there be a join operation for images, should there only be custom combination methods, or should the application layer manage lists of image sets ?\n",
    "  - Example use cases are linear mosaics where a list of small images is combined onto a larger image grid (as an explicit weighted average of images, where the primary beam is used as the weight) and multi-field imaging where main and outlier fields have vastly differing meta-data.\n",
    "\n",
    " \n",
    "### Re-bin and Expand\n",
    "The reverse operation of time/chan average or rebin/regrid operations. Visibility processing methods should (where mathematically possible) support transformations in both directions, with clear conventions implemented.  \n",
    "\n",
    "  - E.g. vis.timeaverage () followed by 'edit flags' and then write back to original dataset ? FLAG value is to be copied during expansion. \n",
    "  - E.g. Caltable solutions need an interpolation to get back to the original data resolution. Interpolation+Extrapolation.\n",
    "\n",
    "\n",
    "### Imaging\n",
    "\n",
    "- Step 1 : A [fully functioning imaging prototype](https://ngcasa.readthedocs.io/en/latest/prototypes.html) exists and has demonstrated imaging weight calculations, basic gridding and image formation using a python-numba implementation. Equivalence with casa6's standard gridder has been established along with a performance comparison and demonstrations on a local workstation (with pre-specified resource constraints) as well as AWS. \n",
    "\n",
    "- Step 2 : Over the next several months, this prototype will be extended to include mosaic gridding/imaging and the design of a fully-featured convolution function cache (based on the casa6 awproject gridder cfcache). Demonstrations will likely include a large ALMA cube mosaic imaging example.\n",
    "\n",
    "- Step 3 : Time permitting, this work will be further extended to include support for heterogenous arrays (dish shapes and pointing offsets) and corresponding demonstrations via ALMA or ngVLA simulations may be written. \n",
    "\n",
    "### Flagging \n",
    "\n",
    "- Step 1 : Implement manual flag commands using native python-based xarray selection syntax and demonstrate that this scales with realistic flag command counts (several 1000 independent data selections).\n",
    "\n",
    "### Calibration \n",
    "- Step 1 : Basic apply w/ single caltable: establish/exercise basic Jones algebra constructs and topology of the fundamental calibration infrastructure (CNGI vs. ngCASA).\n",
    "- Step 2 : General apply of many terms: introduce/establish/exercise multi-term topology, including OTF aggregation of calibration.\n",
    "- Step 3 : Basic solve (no apply): Establish/exercise essential solving mechanics (including pre-averging).\n",
    "- Step 4 : Solve w/ pre-applies: Exercise pre-apply aggregation and resource management and staging to the solve.\n",
    "\n",
    "### Simulation\n",
    "- Step 1 : Generate a simulated dataset to mimic a real observed dataset and show that meta-data are accurate. \n",
    "- Step 2 : If feasible, demonstrate an ngVLA simulation by integrating the simulator meta-data generation with the imager prototype (preferably after full heterogenous array support is ready).\n",
    "\n",
    "\n",
    "### Visualization \n",
    "\n",
    "- Step 1 : Use off-the-shelf python libraries to demonstrate interactive plotting of large volumes of data. \n",
    "\n",
    "- Step 2 : Demonstrate the use of python visualization tools from within an ngCASA application or user script. The purpose is to support flexible interactive visualization as part of algorithms and applications. Features to be included for evaluation for this use case are as follows : \n",
    "\n",
    "  - Array 'versioning' implemented as separately named arrays allows a user to visualize multiple versions (of flags, or corrected_data, or model_Data). The visualization tool should allow the user to specify what (non-default) array names to use/plot.\n",
    "\n",
    "  - On-the-fly visualization must be possible using the currently-available xarray dataset (which may or may not have a zarr counterpart).  \n",
    "   - Flagging : An example use case is [autoflagging](https://ngcasa.readthedocs.io/en/latest/ngcasa_flagging.html#Autoflag-with-extension-and-pre-existing-flags) where it is often useful to inspect flags, discard them, try new autoflag parameters, re-inspect, and save flags only when satisfied. \n",
    "   - Imaging : [Interactive mask drawing and iteration control](https://ngcasa.readthedocs.io/en/latest/ngcasa_imaging.html#Interactive-Clean) editing is another use case.\n",
    "\n",
    "\n",
    "  - Visualization must apply to zarr/xarray datasets such that they are usable (interchangeably, within reason) for visibility datasets, caltables and images. This merges the roles of what has traditionally been separate in casa6 as plotms and the viewer and will get us (at least) scatter and raster displays for all kinds of datasets that we support. \n",
    "\n",
    "\n",
    "\n",
    "### Pipeline Usage Modes\n",
    "\n",
    "- Step 1 : Demonstrate a pipeline use case of operating on a diverse dataset containing multiple meta-data sub-structures (EBs, pointings, etc), with some algorithmic steps being run separately and some on the joint data. Demonstrate the role of the xarray/dask framework in simplifying the management of data selections/splits, parallelization, and combination for imaging. Demonstrate the use of array/flag versions, etc.\n",
    "\n",
    "- Step 2 : String together all the above prototypes into a full pipeline demonstration. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_v8xleeY_9-"
   },
   "source": [
    "## More Information\n",
    "\n",
    "Development environment, process and rules are inherited from CNGI and may be found here:\n",
    "\n",
    "https://cngi-prototype.readthedocs.io/en/latest/development.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ngcasa_development.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
